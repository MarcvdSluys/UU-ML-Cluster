#+title: Cluster stuff for UU ML course

* Introduction
This directory provides the information needed to run your code in a container on the Nikhef cluster with
access to the GPUs.  Some introductory notes on the use of bash (command-line/shell), emacs (text editing),
(Python and) git can be found in [[file:GettingStartedWithBashEmacsPythonAndGit.pdf]].

The [[http://apptainer.org][Singularity/Apptainer]] (the program has been renamed very recently) container provides an environment with
all the required libraries and packages for our machine learning.  While we will develop our code on the
cluster outside the container, it will need to run it /inside/ the container in order for it to find all the
necessary dependencies.  In addition, we need to ~ssh~ into a special node in order to gain access to the GPUs.
Following the steps below should achieve both goals.

* Setting up your environment
We're assuming here that you have logged in to one of the interactive nodes of the Nikhef Stoomboot cluster
using ~ssh~.

** Setting your PATH
The Singularity/Apptainer executable is installed on the share ("network drive") ~/cvmfs/~ and is probably not
in your ~PATH~ (i.e., it won't be found when simply executing ~singularity~).  To remedy that, execute the
following line to add the directory to your ~PATH~ environmental variable
#+begin_src bash
  export PATH=$PATH:/cvmfs/oasis.opensciencegrid.org/mis/singularity/bin
#+end_src
This sets the new value of ~PATH~ as its old value followed by the new directory (separated by a colon).  You
will have to do this every time you log in. However, if you add this line to =~/.bashrc= (i.e. the hidden file
(note the leading dot) ~.bashrc~ in your home directory), it will be executed at every new login.  You can check
whether this worked with
#+begin_src bash
  echo $PATH  # Print the value of the variable PATH
#+end_src

** An alias for singularity
We can now run the ~singularity~ executable.  In order to run the Python script ~script.py~, you have two options.

1) Add the ~#!/usr/bin/env python~ /shebang/ as the first line of your script and make it executable using =chmod
   u+x script.py=.  You can then run it inside and outside the container using
   #+begin_src bash
     ./script.py  # Outside the container
     /cvmfs/oasis.opensciencegrid.org/mis/singularity/bin/singularity run --rocm -B /data,/project,/user --env MPLCONFIGDIR=$HOME/.config/matplotlib /data/datagrid/raaij/tensorflow_rocm/container ./script.py  # Inside the container
   #+end_src
   
2) Do /not/ add the shebang or set the executable bit.  In that case you need to run either of
   #+begin_src bash
     python script.py  # Outside the container
     /cvmfs/oasis.opensciencegrid.org/mis/singularity/bin/singularity run --rocm -B /data,/project,/user --env MPLCONFIGDIR=$HOME/.config/matplotlib /data/datagrid/raaij/tensorflow_rocm/container python ./script.py  # Inside the container
   #+end_src

In both cases above, you can leave out ~/cvmfs/oasis.opensciencegrid.org/mis/singularity/bin/~ if you added that
directory to your ~PATH~ variable.  Still, the command to run your script in a container is quite long, and it
is useful to set an /alias/ to deal with this:
#+begin_src bash
  alias ml_run="/cvmfs/oasis.opensciencegrid.org/mis/singularity/bin/singularity run --rocm -B /data,/project,/user --env MPLCONFIGDIR=$HOME/.config/matplotlib /data/datagrid/raaij/tensorflow_rocm/container"
  alias ml_python="/cvmfs/oasis.opensciencegrid.org/mis/singularity/bin/singularity run --rocm -B /data,/project,/user --env MPLCONFIGDIR=$HOME/.config/matplotlib /data/datagrid/raaij/tensorflow_rocm/container python"
  alias ml_shell="/cvmfs/oasis.opensciencegrid.org/mis/singularity/bin/singularity shell --rocm -B /data,/project,/user --env MPLCONFIGDIR=$HOME/.config/matplotlib /data/datagrid/raaij/tensorflow_rocm/container"
#+end_src
(We threw in the third alias for good measure and due to our prescient abilities.)  Again, it is useful to add
these definitions to your =~/.bashrc=.  Unlike in the case of the ~PATH~ variable, you can choose your own names
here.  Setting an alias basically creates a new command (or macro) which will execute whatever is in the
definition between the quotes after the equal sign.  In this example, running your Python script inside the
container for the two cases above reduces to
#+begin_src bash
  ml_run ./script.py      # When executable
  ml_python ./script.py   # When non-executable
#+end_src

* Running your Python code
As we saw above, using the aliases created earlier, you can edit your Python script ~script.py~ using your
favourite editor on Stoomboot, make it executable if desired, and run it using
#+begin_src bash
  ml_run ./script.py      # When executable
  ml_python ./script.py   # When non-executable
#+end_src

However, from the main Stoomboot nodes (~stbc-i1~ and ~stbc-i2~), you do /not/ have access to the GPUs.  Singularity
will show a warning and your code will not work.  To get access to the GPUs, you need to use a special node.
From Stoomboot, do either one of
#+begin_src bash
  ssh wn-lot-001
  qsub -q gpu-amd -I  # Uses wn-lot-002
#+end_src
This will provide you with an environment that is very similar to that on ~stbc-iX~, but with access to the
GPUs.


